{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。（见5里部分代码）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 语音识别，工业机器人，alpha-go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: git clone到本地； git push提交； git pull拉代码到本地等。两者都是python开发工具，jupyter偏向于演示时使用，pycharm偏向于研发时使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 概率模型是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 语言模型，是一种用来估算句子可能性的模型。由条件概率推导，可以用n-gram方法来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 语音识别时，识别到了多句话，判断那句话才是最合乎逻辑的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 条件概率推导语言模型时，假设每个词的取词概率是相互独立的，那么w_1,w_2,w_3同时出现的概率为w_1,w_2,w_3出现的概率之积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 好处是理解起来比较方便，计算起来也比较方便，但是精确度不够，毕竟每个词的取词概率不可能是完全独立的，会依赖于之前或者之后的词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 条件概率推导语言模型时，假设每个词的取词概率只依赖之前出现的值或之后出现的值，那么多个词同时出现的概率，为一系列两个词相关的条件概率之积，从而可以算出多个词同时出现的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_grammar = '''\n",
    "robot = 诊断结果\n",
    "诊断结果 = 正确 | 错误\n",
    "正确 = 正确原因 ， 礼貌用语 动作 操作物 , 下一步\n",
    "正确原因 = 着装正确 | 着装符合规范\n",
    "礼貌用语 = 请 | 请您\n",
    "动作 = 站到 | 坐到\n",
    "操作物 = 号码 操作物名 方位\n",
    "号码 = 001 | 002 | 003 | 004\n",
    "操作物名 = 柜 | 机柜 | 柜子\n",
    "方位 = 前 | 前方 | 后 | 后方\n",
    "下一步 = 开始操作 | 开始进行操作\n",
    "错误 = 错误原因 ， 停止\n",
    "错误原因 = 着装错误\n",
    "停止 = 请停止操作\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doraemon_grammar = '''\n",
    "doraemon = 称呼 礼貌用语 动作 名词 语气词\n",
    "称呼 = 大熊 | 宜静 | 胖虎\n",
    "礼貌用语 = 请问您 | 请问你\n",
    "动作 = 需要 | 想要 | 要不要\n",
    "名词 = 竹蜻蜓 | 时光机 | 记忆面包\n",
    "语气词 = 吗？ | 啊？\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=>', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    line_list = grammar_str.split(line_split)\n",
    "    for line in line_list:\n",
    "        if not line.strip(): continue\n",
    "        key,value = line.split(split)\n",
    "        grammar[key.strip()] = [i.split() for i in value.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar_1: {'robot': [['诊断结果']], '诊断结果': [['正确'], ['错误']], '正确': [['正确原因', '，', '礼貌用语', '动作', '操作物', ',', '下一步']], '正确原因': [['着装正确'], ['着装符合规范']], '礼貌用语': [['请'], ['请您']], '动作': [['站到'], ['坐到']], '操作物': [['号码', '操作物名', '方位']], '号码': [['001'], ['002'], ['003'], ['004']], '操作物名': [['柜'], ['机柜'], ['柜子']], '方位': [['前'], ['前方'], ['后'], ['后方']], '下一步': [['开始操作'], ['开始进行操作']], '错误': [['错误原因', '，', '停止']], '错误原因': [['着装错误']], '停止': [['请停止操作']]}\n",
      "grammar_2: {'doraemon': [['称呼', '礼貌用语', '动作', '名词', '语气词']], '称呼': [['大熊'], ['宜静'], ['胖虎']], '礼貌用语': [['请问您'], ['请问你']], '动作': [['需要'], ['想要'], ['要不要']], '名词': [['竹蜻蜓'], ['时光机'], ['记忆面包']], '语气词': [['吗？'], ['啊？']]}\n"
     ]
    }
   ],
   "source": [
    "grammar_1 = create_grammar(robot_grammar, '=')\n",
    "print('grammar_1:', grammar_1)\n",
    "grammar_2 = create_grammar(Doraemon_grammar, '=')\n",
    "print('grammar_2:', grammar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target\n",
    "    list = [generate(gram, t) for t in random.choice(gram[target])] # 递归\n",
    "    return ''.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'着装错误，请停止操作'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(grammar_1, 'robot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n, gram, key):\n",
    "    list = []\n",
    "    for i in range(n):\n",
    "        list.append(generate(gram, key))\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['着装错误，请停止操作',\n",
       " '着装错误，请停止操作',\n",
       " '着装正确，请您坐到003机柜后,开始操作',\n",
       " '着装符合规范，请您坐到002柜子前,开始操作',\n",
       " '着装符合规范，请您站到001柜前,开始进行操作',\n",
       " '着装错误，请停止操作',\n",
       " '着装符合规范，请站到003机柜前,开始进行操作',\n",
       " '着装符合规范，请站到004机柜前,开始进行操作',\n",
       " '着装错误，请停止操作',\n",
       " '着装正确，请您站到001机柜前,开始操作']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(10, grammar_1, 'robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['胖虎请问你要不要竹蜻蜓啊？',\n",
       " '大熊请问你要不要记忆面包吗？',\n",
       " '胖虎请问你要不要竹蜻蜓吗？',\n",
       " '胖虎请问您想要竹蜻蜓吗？',\n",
       " '宜静请问你想要记忆面包啊？',\n",
       " '大熊请问你需要记忆面包吗？',\n",
       " '胖虎请问您想要记忆面包吗？',\n",
       " '宜静请问您想要时光机啊？',\n",
       " '大熊请问你要不要时光机啊？',\n",
       " '大熊请问您要不要竹蜻蜓啊？']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(10, grammar_2, 'doraemon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './movie_comments.csv'\n",
    "import pandas as pd\n",
    "content = pd.read_csv(filename, encoding='utf-8')\n",
    "content.head()\n",
    "articles = content['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def token(str):\n",
    "    return re.findall('\\w+', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261497\n"
     ]
    }
   ],
   "source": [
    "articles_clean = [''.join(token(str(a))) for a in articles]\n",
    "print(len(articles_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(str):\n",
    "    return list(jieba.cut(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.987 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心', '想', '吐']\n"
     ]
    }
   ],
   "source": [
    "print(cut(articles_clean[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article_9k.txt', 'w',encoding='utf-8') as f:\n",
    "    for a in articles_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate((open('article_9k.txt',encoding='utf-8'))):\n",
    "    if i % 10000 == 0: print(i)   \n",
    "    TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']\n"
     ]
    }
   ],
   "source": [
    "print(TOKEN[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count['吴京']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word]/len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.85040226776744e-05"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1('吴京')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = [str(i) for i in TOKEN]\n",
    "TOKEN_2 = [TOKEN[i]+TOKEN[i+1] for i in range(len(TOKEN)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想'] ['真让人恶心'] 4751809\n"
     ]
    }
   ],
   "source": [
    "print(TOKEN_2[:10], TOKEN_2[-2:-1],len(TOKEN_2))\n",
    "words_count_2 = Counter(TOKEN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if(word1 + word2) in TOKEN_2: return words_count_2[word1 + word2] / len(TOKEN_2)\n",
    "    else:\n",
    "        return 1/len(TOKEN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1044616902741672e-07\n",
      "2.1044616902741672e-07\n",
      "5.892492732767668e-06\n",
      "2.483264794523517e-05\n"
     ]
    }
   ],
   "source": [
    "print(prob_2('我','想你'))\n",
    "print(prob_2('言情','小说'))\n",
    "print(prob_2('科幻','大片'))\n",
    "print(prob_2('的','地步'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(w_1w_2w_3) = P(w_1w_2)P(w_3|w_1w_2) = P(w_1)P(w_2|w_1)P(w_3|w_1w_2)\\sim P(w_1)P(w_2|w_1)P(w_3|w_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(w_1w_2) = P(w_1)P(w_2|w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_2|w_1)= P(w_1w_2)/P(w_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(w_1w_2w_3) \\sim P(w_1)*(P(w_1w_2)/P(w_1))*P(w_2w_3)/P(w_2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sentence(sentence):\n",
    "    words = cut(sentence)\n",
    "    prob = 1\n",
    "    for (index, w) in enumerate(words[:-1]):\n",
    "        prob *= prob_2(w, words[index + 1])\n",
    "    prob = prob/prob_1(words[-2])\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8993438362047733e-16\n",
      "4.1202487047797206e-14\n",
      "7.485479320560908e-21\n",
      "8.049421127234337e-16\n"
     ]
    }
   ],
   "source": [
    "print(prob_sentence('我喜欢看科幻大片'))\n",
    "print(prob_sentence('大熊是个机器人'))\n",
    "print(prob_sentence('晚上我们一起吃早饭'))\n",
    "print(prob_sentence('晚上我们一起吃晚饭'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar, sentence): # you code here\n",
    "    list = generate_n(10, grammar, sentence)\n",
    "    print(sorted([(s,prob_sentence(s)) for s in list],key = lambda x: x[1], reverse = True)) \n",
    "    return sorted([(s,prob_sentence(s)) for s in list],key = lambda x: x[1], reverse = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('着装错误，请停止操作', 2.043115672854791e-29), ('着装错误，请停止操作', 2.043115672854791e-29), ('着装错误，请停止操作', 2.043115672854791e-29), ('着装错误，请停止操作', 2.043115672854791e-29), ('着装错误，请停止操作', 2.043115672854791e-29), ('着装符合规范，请您坐到002柜后,开始操作', 1.5727084764319176e-69), ('着装符合规范，请坐到002机柜前方,开始操作', 5.242361588106393e-70), ('着装符合规范，请坐到002柜子后,开始进行操作', 1.1794452193548657e-75), ('着装正确，请您坐到001机柜前,开始操作', 3.309704738620423e-76), ('着装符合规范，请您站到002机柜后方,开始操作', 1.3238818954481693e-76)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('着装错误，请停止操作', 2.043115672854791e-29)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(grammar_1, 'robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('大熊请问你想要时光机吗？', 5.2295893606257026e-42), ('胖虎请问你想要时光机啊？', 1.2109278445480944e-42), ('大熊请问你想要竹蜻蜓吗？', 1.0459178721251405e-42), ('宜静请问你需要时光机啊？', 5.845858559887351e-43), ('胖虎请问你需要记忆面包啊？', 1.1691717119774703e-43), ('胖虎请问你需要竹蜻蜓啊？', 1.1691717119774703e-43), ('大熊请问您需要竹蜻蜓吗？', 1.081984005646697e-43), ('大熊请问您想要记忆面包啊？', 2.5053679542374365e-44), ('宜静请问您想要记忆面包啊？', 2.5053679542374365e-44), ('胖虎请问你要不要竹蜻蜓啊？', 2.969444335465765e-47)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('大熊请问你想要时光机吗？', 5.2295893606257026e-42)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(grammar_2, 'doraemon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 最后一步的时候运行有点慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
